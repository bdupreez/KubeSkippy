apiVersion: batch/v1
kind: Job
metadata:
  name: ollama-model-loader
  namespace: kubeskippy-system
spec:
  backoffLimit: 3
  activeDeadlineSeconds: 1800
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: model-loader
        image: curlimages/curl:latest
        command:
        - /bin/sh
        - -c
        - |
          echo "Waiting for Ollama to be ready..."
          max_attempts=60
          attempt=0
          
          while [ $attempt -lt $max_attempts ]; do
            if curl -f -s http://ollama:11434/api/tags >/dev/null 2>&1; then
              echo "Ollama is ready!"
              break
            fi
            echo "Attempt $((attempt+1))/$max_attempts - waiting for Ollama..."
            sleep 10
            attempt=$((attempt+1))
          done
          
          if [ $attempt -eq $max_attempts ]; then
            echo "Failed to connect to Ollama"
            exit 1
          fi
          
          echo "Pulling llama2:7b model..."
          curl -X POST http://ollama:11434/api/pull \
            -H "Content-Type: application/json" \
            -d '{"name":"llama2:7b","stream":false}' \
            --max-time 1200 || exit 1
          
          echo "Model llama2:7b successfully loaded!"